## Overview

The Persistence Framework provides controlled access to the underlying storage mechanisms within Eureka Streams. These storage mechanisms include DB storage, Cache, and Search.

![](images/PF_Persistence-Framework-Component-Diagram.jpg)

## Mappers

Responsibilities:

* Encapsulate data retrieval from both cache and database

The current mapper design provides an API to retrieve DTO objects for business logic use. Mappers attempt to retrieve data first from cache, and if unavailable, attempt to retrieve it from the database. If the mappers have to utilize the database to retrieve information, the resulting DTOs are then fully populated and placed in the cache before being passed back to the client. This design provides encapsulation of caching logic from business logic, and allows business logic to work successfully even in absence of cache, with only a performance degradation. Most mappers are written to allow bulk retrievals to avoid repeated hits to datastores, both db and cache, to improve performance when lists of items are requested.

## Model Design

Eureka model design is based on using [object-relational mapping (ORM)](http://en.wikipedia.org/wiki/Object-relational_mapping) (via [Hibernate](http://en.wikipedia.org/wiki/Hibernate_%28Java%29)) for the system business objects. This has the advantages of abstracting out DB specific procedures from the code and also allowing for potential DB portability. Business relations are modeled via Java annotations which allow the ORM system to create and maintain the system Data Definition Language.

### Model Objects

Responsibilities:

* Define business objects and their relations
* Define database independent schema via ORM.

The model design defines the business objects used within the system. By using Java annotations and ORM, these same objects also define the database schema in a database implementation independent manner, and allow Lucene to index and maintain searchable objects via hibernate search. With these responsibilities, the main model entities are envisioned to be server-side objects only in order to prevent any unneeded dependencies to other areas of the application.

Entities are defined with "lazy-loading" properties so ORM retrieval of the entity involves minimal DB interaction. The preferred way to retrieve specific information is via specific ORM based queries, where the results can be converted directly into DTOs to be cached or sent back to client (see Transformers below). When submitting data, modified entities are retrieved, modified as POJOs and then stored via the ORM system's persistence context mechanism, which not only tracks "dirty" fields of the POJO and saves them, but allows for Lucene index to be automatically updated with current information via Hibernate search. Non-indexed model information can be persisted directly via ORM queries without entity retrieval and persistence, however, care must be taken that this is ONLY done for non-indexed information as this bypasses the hibernate search/lucene interaction.

### Data Transfer Objects (DTOs)

Responsibilities:

* Represent model data as serializable, cacheable objects.
* Potentially denormalize model information based on needs of client.

Eureka Data Transfer Object (DTOs) are the interaction layer between clients and server (note: client request objects are also considered DTOs for the purpose of this document). These objects represent potentially denormalized model data that can be cached and retrieved upon request. This level of indirection between the client/business logic and the model entities provides not only modularity, breaking any dependency on the specific model classes, but also the ability to tailor DTOs for specific client and caching needs to improve performance. Cached DTO objects are normally completely populated from the database before being placed in the cache, unless there are specified exceptions, such as per-user/request information that is added to the DTO before being returned (e.g. is a particular activity starred for a given user). DTO information received from the client is validated and then used to either query for appropriate model objects that can be updated appropriately or used to modify the database directly via ORM queries under certain conditions.

### Transformers

Responsibilities:

* Convert query results to DTOs

Eureka's Transformers are an implementation of Hibernate's ResultTransformer interface, which allow direct query results obtained via HSQL (Hibernate's ORM oriented SQL) or Hibernate's Criteria based queries (programmatic query generation) to be mapped directly to DTO objects. This allows the encapsulation of the conversion logic from the business logic of Eureka. Hibernate has ResultTransformers implementations with similar behavior, but they rely heavily on reflection to reach the same goal. This carries a performance penalty Eureka's transformers can avoid, with trade-off of having slightly more code, by loading properties directly via setters.

## Cache

Caching is an essential element for scalability in the Eureka Streams Architecture. Eureka uses a combination of Write-Through and Write-Behind caching through the [SpyMemcached](http://code.google.com/p/spymemcached/) client for [Memcached](http://memcached.org/). SpyMemcached provides a simple client to access Memcached. Eureka has a small wrapper class that provides access to the SpyMemcached client where CAS (Check and Set) can be implemented for insuring successful cache updates.

### Write-Through Caching

When content is successfully written to the long term data store, a form of that content is immediately persisted to the cache.

### Write-Behind Caching

When content is successfully written to the long term data store, an asynchronous service is used to write a form of the content to the cache. The cache is not immediately updated due to the complexity of certain write procedures.

### Check and Set - CAS

CAS refers to Check and Set on the cache. SpyMemcached's client provides an abstraction for implementing CAS on memcached. The Eureka implementation of the CAS mutator allows Eureka cache mappers to update a list in cache by grabbing the list, updating it, and storing it back into cache. Just before the list is set back into cache, the client checks to be sure that no one else has made any modifications to the list, otherwise the operation fails, this provides an environment for cache writes that is similar to Pessimistic Locking in a database with the absence of locking. Since SpyMemcached writes to the cache asynchronously, the CAS mutator provides some confidence in avoiding dirty writes without locking resources.

### Cache Based Lists as Byte Arrays

The Eureka wrapper for the SpyMemcached client ensures that Lists are stored within the cache as byte arrays. All lists stored in cache for Eureka contain only Long id values that point to other cached serialized entities. Since serialization of a byte array is much faster than a more complicated Java data structure, like a List, reading lists from the cache is extremely fast. There is no need to seek through these lists, but reading and writing individual items to the front of the list are quick. This also reduces the amount of memory needed to store the lists of data that represent the activity streams within Eureka.

## Search

The Eureka search subsystem indexes database entities into the Lucene search engine through the open source Hibernate-Search framework. Entity indexing is performed asynchronously via a JMS queue. Each web node has a full copy of the file system-based search index which is updated on interval from the master copy.

### Lucene Search Index

Lucene is a full-featured text search engine/library. Lucene parses keywords from content, weighting them based on their frequency within the set of all content of that type. Lucene provides a low-level API to provide the ability to index any type of content, so long as it can be converted into searchable text. Every step of the indexing and searching process is swappable, allowing the developer to index the content with word stems, custom abbreviations, synonyms, and much more.

### Hibernate-Search

The Hibernate persistence framework maps model entities to the database, providing an event model that hooks into insert, update, and delete life cycle events. The Hibernate-Search library wraps Lucene's API with a nearly identical interface to the core Hibernate library. Entities marked as search-indexed are automatically reindexed when changed, and Lucene search results are automatically converted back to model entities, providing seamless integration with the rest of the system.

### Master / Slave Index Nodes

In a web farm, entity updates can be triggered from any one of the nodes. Since each web node has a complete copy of the search index, we need to coordinate all changes so that they propagate to each node. When an entity is updated on a web node, Hibernate is configured to send a notification into a JMS queue.

![](images/PF_Lucene_index_queuing_sequence.jpg)

An indexing service listens to that queue and indexes the entities into its master copy of the search index.

On a configurable interval, each web node pulls down a copy of the master search index/copy into a local copy, seamlessly switching to the copy as soon as the copy is complete.

![](images/PF_Lucene_slave-master_index_update.jpg)

### Indexing - Conversion from Entity Fields to Search Tokens

Entities are indexed into the search engine based on how they'll be queried at run time, so planning is required. The index can be searched based on weighted fields that don't necessarily need to map directly to entity fields. These fields may be of any type, may combine entity fields, or be derived from them. Low-level java types such as strings and numbers can be automatically converted to searchable text, but custom types and dates should be converted programmatically with custom Lucene "string bridges".

After the text is extracted from the domain model, its run through one or more Lucene tokenizers and analyzers. Tokenizers perform tasks such as breaking words apart based on punctuation and spaces while analyzers perform tasks such as remove common english words, add synonyms, and stem words (convert plural to singular). Lucene provides standard tokenizers and analyzers, and allows the developer to write custom ones.

Example:

    Entity content: "Eureka - connecting people."
    Tokenized as: "eureka", "connecting", "people"
    Analyzed as: "eureka", "connect", "person"

The parsed content is stored in Lucene search fields which don't need to map directly to the entity fields. It's a good practice, for example, to generalize the fields so that multiple entity types can be searched at the same time. Examples: "title", "description", "author".

![](images/PF_Indexing-Sequence-Diagram.jpg)

### Searching

One searches through the Lucene search index with the Hibernate-Search framework. Lucene fields can be weighted individually, for example, to ensure that a person with the last name of "James" ranks higher than someone with the same first name. The search terms are fed through the same tokenizers and analyzers as the content was on index. This is necessary in cases where words are stemmed, so a search for "people" matches the indexed content, "person".

### Mapping Search Results to Entities

By default, Hibernate-Search returns entity class names and (primary key) ids from the search index, then loads those entities from the database via the Hibernate-Core framework. In the Eureka framework, we avoid this secondary database hit by implementing our own search result transformers, loading the ModelView data transfer objects (DTO) through our cache/db framework. If the DTO exists in cache, it's immediately returned. If not, it's loaded from database, inserted in cache, and returned. We add additional performance gains by using custom object factories, rather than use reflection to build our entities.

![](images/PF_Hibernate_Search_sequence.jpg)

### Performance

The following factors of the search subsystem benefit the indexing and search performance:

* each web node has a full, local copy of the entire search index
* the index doesn't contain the full content in the search index for retrieval, just the keyword metrics
* search indexing takes place asynchronously via a job queue and indexing server
* avoiding the database hit by using cache
* using factories rather than reflection to generate entities from search results

Adding a new web node/cache server helps this subsystem scale somewhat linearly.

## Database

The database for Eureka Streams provides long term storage. The application looks to cache for the majority of content served to the client, but cache is volatile and needs to rely on a stable storage mechanism. For Eureka Streams, the database connection is configured within Spring. Spring also provides an EntityManager that is injected into the mappers that connects the application to the database without having to manage the database connection directly. Eureka Streams relies on Hibernate annotations within the model to describe the schema. On initial installation; however, the database is generated through a series of database scripts. These scripts contain the schema as well as initial state data.

### Database Connection

Configured within Spring, the database connection uses a standard JDBC driver for access Postgres by default. That connection is then injected by spring through the PersistenceContext property of the BaseDomainMapper using a simple annotation on the property definition.

### EntityManager

Once the database connection is established, the Spring EntityManager is passed into the BaseDomainMapper as the PersistenceContext. The EntityManager wraps Hibernate and provides access to the underlying ORM API's. The EntityManager also ensure connection into the transactions defined within the Action Framework.

### Database Scripts

The database scripts are written SQL and are intended to provide an upgrade mechanism for the database schema as well as data. These scripts follow a very specific structure and are run automatically during deployment to ensure that the database is up to the correct version along with the software.